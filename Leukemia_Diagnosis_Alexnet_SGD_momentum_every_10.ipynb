{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Leukemia_Diagnosis_Alexnet_SGD_momentum_every_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gamesMum/Leukemia-Diagnostics/blob/master/Leukemia_Diagnosis_Alexnet_SGD_momentum_every_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN0FVnXEWjFL",
        "colab_type": "text"
      },
      "source": [
        "# **Leukemia Diagnosis**\n",
        "\n",
        "**Classification of Acute Leukemia using Pretrained Deep Convolutional Neural Networks**\n",
        "Based on the implementation in the paper:\n",
        "\n",
        "[**Human-level recognition of blast cells in acute myeloid\n",
        "leukemia with convolutional neural networks**](https://www.biorxiv.org/content/10.1101/564039v1.full.pdf)\n",
        "\n",
        " **The Dataset used in this implementation:**\n",
        "\n",
        "\n",
        "- The dataset is for AML instead of ALL\n",
        "-The number of subtypes are 16\n",
        "including the Normal class  \n",
        "\n",
        "- link to the dataset https://www.kaggle.com/rashasalim/blood-smear-images-for-aml-diagnosis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wonfAPXyWjFN",
        "colab_type": "text"
      },
      "source": [
        "# **Materials and Methods**\n",
        "\n",
        "- peripheral blood smears were selected from 100 patients diagnosed with different subtypes\n",
        "of AML at the Laboratory of Leukemia Diagnostics at Munich University Hospital between 2014 and 2017, and smears from 100 patients found to exhibit no morphological\n",
        "features of hematological malignancies in the same time frame.\n",
        "\n",
        "- The resulting digitised data consisted of multiresolution pyramidal images of a size of approximately 1 GB per scanned area of interest.\n",
        "A trained examiner experienced in routine cytomorphological diagnostics at Munich University Hospital differentiated physiological and pathological leukocyte types contained\n",
        "in the microscopic scans into the classification scheme (see fig 2B),\n",
        "which is derived from standard morphological categories and was refined to take into account subcategories relevant for the morphological classification of AML, such as bilobed Promyelocytes, which are typical of the FAB subtype M3v.\n",
        "-  Annotation was carried out on a\n",
        "single-cell basis, and approximately 100 cells were differentiated in each smear\n",
        "- Subimage patches of size 400 x 400 pixels (corresponding to approximately 29µm x 29µm)\n",
        "around the annotated cells were extracted without further cropping or filtering, including\n",
        "background components such as erythrocytes, platelets or cell fragments.\n",
        "- When examining the screened blood smears, the cytologist followed the routine clinical procedure.\n",
        "Overall, 18,365 single-cell images were annotated and cut out of the scan regions.\n",
        "\n",
        "- Annotations of single-cell images provide the ground truth for training and evaluation\n",
        "of our network.\n",
        "\n",
        "- Morphological classes containing fewer than 10 images were merged with\n",
        "neighbouring classes of the taxonomy.\n",
        "\n",
        "- A subset of 1,905 single-cell images from all morphological categories were presented to a second, independent examiner, and annotated\n",
        "for a second time in order to estimate inter-rater variability\n",
        "\n",
        "**For Implementation:**\n",
        "-\tThe network was adopted  to input image dimensions of 400 x 400 x 3\n",
        "-\tNo further cropping or ﬁltering.\n",
        "-\tRetained the cardinality hyper-parameter at C = 32.\n",
        "-\tThe ﬁnal dense layer adapted to our 10-category classiﬁcation scheme.\n",
        "-\tAnnotations of single-cell images provide the ground truth for training and evaluation of the network\n",
        "-\tThere are 10 classes for training and evaluation.\n",
        "-\tFor our image classiﬁcation task, we used a Alexnet\n",
        "-\tThe network was trained for at least 20 epochs, which took a computing time of approximately 4 days on a Nvidia GeForce GTX TITAN X GPU.\n",
        "-\tThe test group contains 20%, and the validation group 20% of the images\n",
        "-\tRandom rotational transformations of 0−359 degrees, as well as random horizontal and vertical ﬂips to the single-cell images in the dataset.\n",
        "-\tIn the end the data set was augmented in such a way that each class contained approximately 10,000 images for training. (This is from the origional paper that had 15 classes, but this number increased in this implementation since some of the classes were combined)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "q0AXFPaHWjFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inporting the necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yCYxej8wWjFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "330323b6-3418-4ddc-b467-7df7445072d1"
      },
      "source": [
        "#check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if train_on_gpu:\n",
        "    print(\"CUDA is available. Training on GPU!\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Training on CPU.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is not available. Training on CPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vyWr_2gkWjFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#time to prepare the data\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision as tv\n",
        "\n",
        "batch_size = 32\n",
        "test_size = 0.2\n",
        "valid_size = 0.2\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "\n",
        "#define the transforms\n",
        "train_transform  = transforms.Compose([transforms.Resize((400,400)),\n",
        "                                       transforms.RandomRotation(359),\n",
        "                                       transforms.RandomHorizontalFlip(0.2),\n",
        "                                       transforms.RandomVerticalFlip(0.2),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((400, 400)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "train_data = datasets.ImageFolder(\"/kaggle/input/single-cell-morphological-dataset-of-leukocytes/blood_smear_images_for_aml_diagnosis_MOD/AML-Cytomorphology_LMU_MOD\",\n",
        "                                  transform = train_transform)\n",
        "\n",
        "#obtain training indicies that will be used as testing and validation\n",
        "\n",
        "num_train = len(train_data)\n",
        "indicies = list(range(num_train))\n",
        "np.random.shuffle(indicies)\n",
        "split = int(np.floor(valid_size+test_size * num_train))\n",
        "train_idx, test_idx, valid_idx = indicies[split:], indicies[:int(split/2)], indicies[int(split/2):split]\n",
        "#define samplers for obtainig the trainig, testing and validation set\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           sampler = train_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                          sampler = test_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                          sampler = valid_sampler)\n",
        "\n",
        "\n",
        "#  PROMYELOCYTE (PMB Promyelocyte (bilobled))\n",
        "# PMO Promyelocyte), MYELOCYTE (MYB Myelocyte, MYO Myeloblast)ARE FOUND ON LEUKEMIA PATIENTS \n",
        "classes = ['BAS', 'EBO', 'EOS', 'KSC','LYT','MON', 'MYO', 'NGB', 'NGS', 'PMO']\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CS_pZ--5WjFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "  img = img /2+0.5 #unormalize the images\n",
        "  plt.imshow(np.transpose(img, (1, 2, 0))) #convert it back from tensor to image\n",
        "\n",
        "#get one batch of training images\n",
        "dataiter = iter(train_loader) #now contains the first batch\n",
        "images, labels = dataiter.next() #images=the first batch of images, labels= the first batch of labels\n",
        "images = images.numpy() #convert the images to display them\n",
        "\n",
        "#plot the imahes in the batch along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "\n",
        "for idx in np.arange(5):\n",
        "  ax = fig.add_subplot(1, 5, idx+1, xticks=[], yticks=[]) #(rows, cols, index, .., ..)\n",
        "  imshow(images[idx])\n",
        "  ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6LBKyQudWjFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load AlexNet pretrained model\n",
        "model = models.alexnet(pretrained=True)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fdojWvoFWjFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#freeze the model calssifier\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(9216, 4096)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout', nn.Dropout(0.5)),\n",
        "                          ('fc2', nn.Linear(4096, 4096)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout', nn.Dropout(0.5)),\n",
        "                          ('fc3', nn.Linear(4096, 1024)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout', nn.Dropout(0.5)),\n",
        "                          ('fc4', nn.Linear(1024, 10)),\n",
        "                          ('output', nn.LogSoftmax(dim=1) )                                       \n",
        "                                      ]))\n",
        "\n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5jEN7NvFWjFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "#Loss function and optmixation function\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z-9Y4o_nWjF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of epochs to train the model\n",
        "import numpy as np\n",
        "n_epochs = 200\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(images)\n",
        "        # calculate the batch loss (comapre the values of the output model to the actual labels)\n",
        "        loss = criterion(output, labels)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for images, labels in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(images)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, labels)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*images.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    \n",
        "    if epoch % 10 == 0:    \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "    \n",
        "        # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min, \n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), 'model_AML_classifier.pt')\n",
        "            valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "igFWzdZiWjF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('model_AML_classifier.pt'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O2egxlCbWjGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize the test loss\n",
        "test_loss = 0.0\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list (0. for i in range(10))\n",
        "\n",
        "#set the model to test and validation mode (no gradient descent needed)\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "  #move the tensor to GPU ig available\n",
        "  if train_on_gpu:\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "  #forward pass: compute prediction output by passing the first batch of test data\n",
        "  output = model(data)\n",
        "  #calculate the batch size\n",
        "  loss = criterion(output, target)\n",
        "  #update the test loss\n",
        "  test_loss += loss.item()*data.size(0)\n",
        "  #convert output probabilities to output class\n",
        "  _, pred = torch.max(output, 1)\n",
        "  #compare the prediction to true label\n",
        "  correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "  #conveert to numpy array and remove the extra dimention and get only the result\n",
        "  correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "  #calculate test accuracy for each object class\n",
        "  for i in range(batch_size):\n",
        "    try:\n",
        "      label = target.data[i] #get the corresponding label from the object\n",
        "      class_correct[label] += correct[i].item()\n",
        "      class_total[label] += 1\n",
        "    except IndexError:\n",
        "      break\n",
        "  \n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "  if class_total[i] > 0:\n",
        "     print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "  else:\n",
        "       print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n",
        "   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gLH_LoxyWjGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualizing a sample tested of data\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "images.numpy()\n",
        "\n",
        "#Move model inputs to cuda\n",
        "if train_on_gpu:\n",
        "    images = images.cuda()\n",
        "\n",
        "#get sample outputs\n",
        "output = model(images)\n",
        "#convert probabilties to prediction class\n",
        "_, preds_tensor = torch.max(output, 1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(10):\n",
        "    ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images.cpu()[idx])\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "noKZVvhRWjGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing the result\n",
        "# draw testing vs validation error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hzT5-OdWWjGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}